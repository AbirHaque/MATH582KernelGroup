{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('DiabetesBinaryClassification.csv')\n",
    "# df = pd.read_csv('data.csv', header=None)\n",
    "\n",
    "# Preprocessing data\n",
    "df = df.drop_duplicates()\n",
    "df = df.dropna()\n",
    "for series_name, series in df.items():\n",
    "  df[series_name] = series.astype('float')\n",
    "\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "for data in df.values:\n",
    "    X.append( np.array( data[ : -1 ], dtype = float ) )\n",
    "    y.append( [ data[ -1 ] ] )\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = np.asarray( X )\n",
    "y = np.asarray( y )\n",
    "\n",
    "for idn,n in np.ndenumerate(y):\n",
    "  if n == 0:\n",
    "    y[idn] = -1\n",
    "\n",
    "# X = np.array(df.iloc[:, [0,1]])\n",
    "# y = np.array(df.iloc[:, 2])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.3704e+02 -9.7050e+01  4e+03  3e+01  2e-10\n",
      " 1: -2.2432e+01 -9.2442e+01  2e+02  1e+00  2e-10\n",
      " 2: -1.6742e+01 -5.4403e+01  5e+01  2e-01  3e-11\n",
      " 3: -1.7610e+01 -2.4022e+01  7e+00  2e-02  2e-11\n",
      " 4: -1.9137e+01 -2.1206e+01  2e+00  5e-03  2e-11\n",
      " 5: -1.9605e+01 -2.0550e+01  1e+00  1e-03  2e-11\n",
      " 6: -1.9804e+01 -2.0266e+01  5e-01  6e-04  2e-11\n",
      " 7: -1.9947e+01 -2.0068e+01  1e-01  1e-04  3e-11\n",
      " 8: -1.9991e+01 -2.0010e+01  2e-02  1e-05  3e-11\n",
      " 9: -1.9999e+01 -2.0001e+01  2e-03  1e-06  3e-11\n",
      "10: -2.0000e+01 -2.0000e+01  4e-05  3e-08  2e-11\n",
      "11: -2.0000e+01 -2.0000e+01  8e-07  3e-10  3e-11\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "from cvxopt import matrix, solvers\n",
    "\n",
    "def fit_model(X_train: np.array, y_train: np.array, C: float=0.1) -> tuple[int,int]:\n",
    "  X_train = np.asarray( X_train )\n",
    "  m, n = X_train.shape\n",
    "  K = np.matmul(X_train, X_train.T)\n",
    "  P = matrix(np.matmul(y_train,y_train.T) * K)\n",
    "  q = matrix(np.ones((m, 1)) * -1)\n",
    "  A = matrix((y_train.reshape(1, -1)))\n",
    "  b = matrix(np.zeros(1))          \n",
    "  G = matrix(np.vstack((np.eye(m) * -1, np.eye(m))))        \n",
    "  h = matrix(np.hstack((np.zeros(m), np.ones(m) * C)))\n",
    "\n",
    "  sol = solvers.qp(P, q, G, h, A, b)\n",
    "  alphas = np.array(sol[\"x\"])\n",
    "\n",
    "  w = np.dot((y_train * alphas).T, X_train)[0]\n",
    "  S = (alphas > 1e-5).flatten()\n",
    "  b = np.mean(y_train[S] - np.dot(X_train[S], w.reshape(-1,1)))\n",
    "  return w,b\n",
    "\n",
    "w,b = fit_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7545691906005222\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def evaluate_model(X_test: np.array, y_test: np.array, w: np.array, b: float):\n",
    "  X_test = np.asarray( X_test )\n",
    "  n_test = X_test.shape[0]\n",
    "  prod = np.dot(X_test,w) + np.full(n_test,b)\n",
    "  y_pred = np.sign(prod)\n",
    "\n",
    "  # Model Accuracy: how often is the classifier correct?\n",
    "  print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "evaluate_model(X_test, y_test, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manojturaga/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.762402088772846\n",
      "Precision: 0.7263157894736842\n",
      "Recall: 0.5149253731343284\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
